{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC 591-G8-Speaker Recognition",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssandanshi/Speaker-Recognition/blob/master/CSC_591_G8_Speaker_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIhcp_zSutZ2",
        "colab_type": "code",
        "outputId": "8f025b9f-a935-45a5-e323-fcf0d28caf35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W2E-U1mGfX4",
        "colab_type": "code",
        "outputId": "e6b9cd1b-eeff-4e12-9790-a18a03db7d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.6/dist-packages (0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "usdN3jU2nYw2"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_PrwnIySnYws",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import keras.backend as K\n",
        "import keras\n",
        "from python_speech_features import fbank, delta\n",
        "import operator\n",
        "from collections import OrderedDict\n",
        "from multiprocessing import Pool\n",
        "from time import time\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iORWv-ZcnRan",
        "colab_type": "text"
      },
      "source": [
        "# Reading Data and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbuVgQY7ndA1",
        "colab_type": "text"
      },
      "source": [
        "## Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uust2hjFtzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constant to be used throughout the code\n",
        "sample_rate = 12000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxJ0hHhmPZ_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_audio(filename,sample_rate):\n",
        "  audio, _ = librosa.load(filename, sr=sample_rate, mono=True)\n",
        "  return audio.flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f6_dlTymU1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_frames(m,epsilon=1e-12):\n",
        "    return [(v - np.mean(v)) / max(np.std(v),epsilon) for v in m]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNLtTFa7Og58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_audio(filename, cnn=True):\n",
        "  audio = read_audio(filename,sample_rate)\n",
        "  # capture audio only from second 1 to second 5\n",
        "  start_sec, end_sec = 1,5\n",
        "  start_frame = int(start_sec * sample_rate)\n",
        "  end_frame = int(end_sec * sample_rate)\n",
        "  audio = audio[start_frame:end_frame]\n",
        "\n",
        "  #Padding with zeros if audio length less than 4 secs\n",
        "  if len(audio)<(end_frame-start_frame):\n",
        "    au = [0]*(end_frame-start_frame)\n",
        "    for i in range(len(audio)):\n",
        "        au[i] = audio[i]\n",
        "    audio = np.array(au)\n",
        "  #print(len(audio),sample_rate)\n",
        "\n",
        "  filter_banks, energies = fbank(audio, samplerate=sample_rate, nfilt=64, winlen=0.025) #filter_bank (num_frames , 64),energies (num_frames ,)\n",
        "  #Standardize with mean and std\n",
        "  filter_banks = normalize_frames(filter_banks)\n",
        "  #print(\"filterbanks:\" + str(len(filter_banks)))\n",
        "  frames_features = filter_banks\n",
        "\n",
        "  num_frames = len(frames_features)\n",
        "  #print(num_frames)\n",
        "  return np.reshape(np.array(frames_features),(num_frames, 64, 1))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOP0aTz6fzqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "This function will read the data into a dataframe.\n",
        "If the pattern is  .wav and flag is false, It will read the actual audio files (before preprocessing)\n",
        "If flag is True and pattern is npy, It will read preprocessed files stored as npy (numpy arrays)\n",
        "'''\n",
        "def create_catalogue(path,pattern=\"*/*.wav\",flag=False):\n",
        "  data = pd.DataFrame()\n",
        "  data['filename'] = glob.glob(os.path.join(path, pattern), recursive=True)\n",
        "  if not flag:\n",
        "    data['class'] = data['filename'].apply(lambda x: x.split(\"/\")[1])\n",
        "  else:\n",
        "    data['class'] = data['filename'].apply(lambda x: x.split(\"/\")[1].split('_')[0])\n",
        "  num_speakers = len(data['class'].unique())\n",
        "  print('Retrieved {} files with {} different speakers.'.format(str(len(data)), str(num_speakers)))\n",
        "  # print(data.head(10))\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcxKC8OCiS0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#catalog = create_catalogue(\"subset3_npy\",\"*.npy\",True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG8SHMH8nMln",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8kXp9bheVvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Used to preprocess a batch of files using. To be run inside each thread of he Mutlpithread preprocess call.\n",
        "def preprocess_batch(data,out_dir=\"subset2_npy\",task_num=\"0\"):\n",
        "  start_time = time()\n",
        "  i=0\n",
        "  for i in range(len(data)):\n",
        "    orig_time = time()\n",
        "    filename = data.iloc[i]['filename']\n",
        "    target_filename = out_dir+\"/\" + filename.split(\"/\")[1]+\"_\"+filename.split(\"/\")[-1].split('.')[0] + '.npy'\n",
        "    \n",
        "    if os.path.exists(target_filename):\n",
        "      if i % 10 == 0: print(\"Task ID:{0} File No.: {1} Existing File Name:{2}\".format(task_num, i, filename))\n",
        "      continue\n",
        "    feature = load_audio(filename)\n",
        "    #print('!!!',feature.ndim,feature.shape[0],feature.shape[1],feature.shape[2])\n",
        "    if feature.ndim != 3 or feature.shape[0] < 399 or feature.shape[1] !=64 or feature.shape[2] != 1:\n",
        "      print('Error in loading file:',filename)\n",
        "      continue\n",
        "    np.save(target_filename, feature)\n",
        "    if i % 100 == 0:\n",
        "      print(\"Task ID:{0} Time taken per file: {1:.3f}s Current File No.:{2} File name:{3}\".format(task_num, time() - orig_time, i, filename))\n",
        "  print(\"Task ID {} with {} files completed in {} seconds.\".format(task_num, i, time()-start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfr2WKALdBrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Master preprocessing function. Runs 10 threads in parralel to perform Feature Preprocessing.\n",
        "def preprocess(data_dir,out_dir):\n",
        "  orig_time = time()\n",
        "  data = create_catalogue(data_dir)\n",
        "  print(\"STARTING PREPROCESSING\")\n",
        "  print(\"Starting 10 threads to exttra ct audio, feature banks and store as npy files.\")\n",
        "  p = Pool(10)\n",
        "  print(len(data))\n",
        "  patch = int(len(data)/10)\n",
        "  for i in range(10):\n",
        "      if i < 9:\n",
        "          sdata=data[i*patch: (i+1)*patch]\n",
        "      else:\n",
        "          #Last patch gets leftover data\n",
        "          sdata = data[i*patch:]\n",
        "      p.apply_async(preprocess_batch, args=(sdata,out_dir,i))\n",
        "  print('Waiting for all subprocesses done...')\n",
        "  p.close()\n",
        "  p.join()\n",
        "\n",
        "  print(\"Preprocessing Finished. Took {} seconds\".format(time()-orig_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9d1kmkNm81H",
        "colab_type": "text"
      },
      "source": [
        "### Running the preprocessing on original data. We have shared the output of this in form of npy files in order to save computation time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLs_bYmEkz1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocess(\"subset2\",\"subset3_npy\")\n",
        "#!zip -rq subset3_npy.zip subset3_npy\n",
        "#!cp subset3_npy.zip drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94RoFFLEpywG",
        "colab_type": "text"
      },
      "source": [
        "Reading saved npy files from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKDXvs--QXf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp drive/My\\ Drive/subset3_npy.zip .\n",
        "# !unzip -q subset3_npy.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COOx4b6AqJf4",
        "colab_type": "code",
        "outputId": "65167160-3d09-4191-bbcc-30cb5e57f575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "catalog = create_catalogue(\"subset3_npy\",\"*.npy\",True)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieved 44998 files with 300 different speakers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkgdyynVqLM1",
        "colab_type": "text"
      },
      "source": [
        "# Training Triplet Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4yKKgDNP62x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_FRAMES=399\n",
        "BATCH_SIZE=32\n",
        "TRIPLET_PER_BATCH=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANbGoKdytwk3",
        "colab_type": "text"
      },
      "source": [
        "## Creating Mini Batches\n",
        "refer to report for details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEtQ7krRPcUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clipped_audio(x, num_frames=NUM_FRAMES):\n",
        "    if x.shape[0] > num_frames:\n",
        "        bias = np.random.randint(0, x.shape[0] - num_frames)\n",
        "        clipped_x = x[bias: num_frames + bias]\n",
        "    else:\n",
        "        clipped_x = x\n",
        "\n",
        "    return clipped_x\n",
        "\n",
        "\n",
        "class MiniBatch:\n",
        "    def __init__(self, data, batch_size, unique_speakers=None):    \n",
        "        if unique_speakers is None:\n",
        "            unique_speakers = list(data['class'].unique())\n",
        "        num_triplets = batch_size\n",
        "\n",
        "        anchor_batch = None\n",
        "        positive_batch = None\n",
        "        negative_batch = None\n",
        "        for ii in range(num_triplets):\n",
        "            two_different_speakers = np.random.choice(unique_speakers, size=2, replace=False)\n",
        "            anchor_positive_speaker = two_different_speakers[0]\n",
        "            negative_speaker = two_different_speakers[1]\n",
        "            #print(two_different_speakers)\n",
        "            anchor_positive_file = data[data['class'] == anchor_positive_speaker].sample(n=2, replace=False)\n",
        "            anchor_df = pd.DataFrame(anchor_positive_file[0:1])\n",
        "            anchor_df['training_type'] = 'anchor'\n",
        "            positive_df = pd.DataFrame(anchor_positive_file[1:2])\n",
        "            positive_df['training_type'] = 'positive'\n",
        "            negative_df = data[data['class'] == negative_speaker].sample(n=1)\n",
        "            negative_df['training_type'] = 'negative'\n",
        "\n",
        "            if anchor_batch is None:\n",
        "                anchor_batch = anchor_df.copy()\n",
        "            else:\n",
        "                anchor_batch = pd.concat([anchor_batch, anchor_df], axis=0)\n",
        "            if positive_batch is None:\n",
        "                positive_batch = positive_df.copy()\n",
        "            else:\n",
        "                positive_batch = pd.concat([positive_batch, positive_df], axis=0)\n",
        "            if negative_batch is None:\n",
        "                negative_batch = negative_df.copy()\n",
        "            else:\n",
        "                negative_batch = pd.concat([negative_batch, negative_df], axis=0)\n",
        "\n",
        "        self.data_batch = pd.DataFrame(pd.concat([anchor_batch, positive_batch, negative_batch], axis=0))\n",
        "        self.num_triplets = num_triplets\n",
        "\n",
        "    def to_inputs(self,le=None):\n",
        "\n",
        "        new_x = []\n",
        "        for i in range(len(self.data_batch)):\n",
        "            filename = self.data_batch.iloc[i]['filename']\n",
        "            x = np.load(filename)\n",
        "            new_x.append(x)\n",
        "        x = np.array(new_x) #(batchsize, num_frames, 64, 1)\n",
        "        y = self.data_batch['class'].values\n",
        "        if le is not None:\n",
        "          y = le.transform(y)\n",
        "          no_of_speakers = len(le.classes_)\n",
        "          y = np.eye(no_of_speakers)[y_]    #one-hot\n",
        "\n",
        "        # anchor examples [speakers] == positive examples [speakers]\n",
        "        np.testing.assert_array_equal(y[0:self.num_triplets], y[self.num_triplets:2 * self.num_triplets])\n",
        "        return x, y\n",
        "\n",
        "\n",
        "def stochastic_mini_batch(data, batch_size=BATCH_SIZE,unique_speakers=None):\n",
        "    mini_batch = MiniBatch(data, batch_size,unique_speakers)\n",
        "    return mini_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsyq7-trUGbV",
        "colab_type": "code",
        "outputId": "11c1d501-8a2c-41da-a39d-37320ec798ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_npy = create_catalogue(\"subset3_npy\",\"*.npy\",flag=True) \n",
        "unique_speakers = data_npy[\"class\"].unique()\n",
        "batch = stochastic_mini_batch(data_npy, batch_size=BATCH_SIZE, unique_speakers=unique_speakers)\n",
        "batch_size = BATCH_SIZE * TRIPLET_PER_BATCH\n",
        "x, y = batch.to_inputs()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieved 44998 files with 300 different speakers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdvPE-xjUF9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finding input shape\n",
        "audio_file = x[0]\n",
        "num_frames = audio_file.shape[0]\n",
        "train_batch_size = batch_size\n",
        "#batch_shape = [batch_size * num_frames] + list(audio_file.shape[1:])  # A triplet has 3 parts.\n",
        "input_shape = (num_frames, audio_file.shape[1], audio_file.shape[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCT2MN2pWbEk",
        "colab_type": "text"
      },
      "source": [
        "# Pretraining Input Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F65PpQq3Wywz",
        "colab_type": "code",
        "outputId": "b4ee3de2-87fb-44b8-ecd1-2af6362c041d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(data_npy[\"class\"])"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oQXQo7AzRw0",
        "colab_type": "text"
      },
      "source": [
        "### Loading Mini batches \n",
        "used to load train and test data as iterators/generators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEjDyxr0X0ce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_from_list(x_paths, batch_start, limit, le):\n",
        "    x = []\n",
        "    y_ = []\n",
        "    for i in range(batch_start, limit):\n",
        "        x.append(np.load(x_paths[i]))\n",
        "        y_.append(x_paths[i].split(\"/\")[-1].split(\"_\")[0])\n",
        "    y_ = le.transform(y_)\n",
        "    no_of_speakers = len(le.classes_)\n",
        "    x = np.asarray(x)\n",
        "    y = np.eye(no_of_speakers)[y_]    #one hot encoding\n",
        "    y = np.asarray(y)\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KIEDFQkXegN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_training_data_generator(paths, le, batch_size=BATCH_SIZE * TRIPLET_PER_BATCH):\n",
        "  L = len(paths)\n",
        "  while True:\n",
        "    np.random.shuffle(paths)\n",
        "    batch_start = 0\n",
        "    batch_end = batch_size\n",
        "\n",
        "    while batch_end < L:\n",
        "      x_train_t, y_train_t = load_from_list(paths, batch_start, batch_end, le)\n",
        "      randnum = random.randint(0, 100)\n",
        "      random.seed(randnum)\n",
        "      random.shuffle(x_train_t)\n",
        "      random.seed(randnum)\n",
        "      random.shuffle(y_train_t)\n",
        "      yield (x_train_t, y_train_t)\n",
        "      batch_start += batch_size\n",
        "      batch_end += batch_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FAO5ItdYGvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_test_data_generator(paths, le, batch_size=BATCH_SIZE * TRIPLET_PER_BATCH):\n",
        "  L = len(paths)\n",
        "  while True:\n",
        "    np.random.shuffle(paths)\n",
        "    batch_start = 0\n",
        "    batch_end = batch_size\n",
        "\n",
        "    while batch_end < L:\n",
        "      x_test_t, y_test_t = load_from_list(paths, batch_start, batch_end, le)\n",
        "      yield (x_test_t, y_test_t)\n",
        "      batch_start += batch_size\n",
        "      batch_end += batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiil2lo2YXJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(files, labels, batch_size):\n",
        "  test_size = max(batch_size/len(labels),0.05)\n",
        "  train_paths, test_paths, y_train, y_test = train_test_split(files, labels, test_size=test_size, random_state=42)\n",
        "  return np.array(train_paths), np.array(test_paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yasIu1_qX6Go",
        "colab_type": "text"
      },
      "source": [
        "# CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksqaoGVCX7hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "import math\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras.layers import Input, GRU\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.core import Lambda, Dense, RepeatVector\n",
        "from keras.layers.core import Reshape\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjeG9pi7YRMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#restrictting input to range (0,20) - Clipping the ReLU\n",
        "def clipped_relu(inputs):\n",
        "    return Lambda(lambda y: K.minimum(K.maximum(y, 0), 20))(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKKFBiPXYPfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    conv_name_base = 'res{}_{}_branch'.format(stage, block)\n",
        "\n",
        "    x = Conv2D(filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   strides=1,\n",
        "                   activation=None,\n",
        "                   padding='same',\n",
        "                   kernel_initializer='glorot_uniform',\n",
        "                   kernel_regularizer=regularizers.l2(l=0.00001),\n",
        "                   name=conv_name_base + '_2a')(input_tensor)\n",
        "    x = BatchNormalization(name=conv_name_base + '_2a_bn')(x)\n",
        "    x = clipped_relu(x)\n",
        "\n",
        "    x = Conv2D(filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   strides=1,\n",
        "                   activation=None,\n",
        "                   padding='same',\n",
        "                   kernel_initializer='glorot_uniform',\n",
        "                   kernel_regularizer=regularizers.l2(l=0.00001),\n",
        "                   name=conv_name_base + '_2b')(x)\n",
        "    x = BatchNormalization(name=conv_name_base + '_2b_bn')(x)\n",
        "\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = clipped_relu(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUqH6fZKYdYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_model(input_shape=(NUM_FRAMES,64, 1),    #input_shape(32,32,3)\n",
        "                        batch_size=BATCH_SIZE * TRIPLET_PER_BATCH , num_frames=NUM_FRAMES):\n",
        "    # http://cs231n.github.io/convolutional-networks/\n",
        "    # conv weights\n",
        "    # #params = ks * ks * nb_filters * num_channels_input\n",
        "\n",
        "    # Conv128-s\n",
        "    # 5*5*128*128/2+128\n",
        "    # ks*ks*nb_filters*channels/strides+bias(=nb_filters)\n",
        "\n",
        "    # take 100 ms -> 4 frames.\n",
        "    # if signal is 3 seconds, then take 100ms per 100ms and average out this network.\n",
        "    # 8*8 = 64 features.\n",
        "\n",
        "    # used to share all the layers across the inputs\n",
        "\n",
        "    # num_frames = K.shape() - do it dynamically after.\n",
        "\n",
        "    def conv_and_res_block(inp, filters, stage):\n",
        "        conv_name = 'conv{}-s'.format(filters)\n",
        "        o = Conv2D(filters,\n",
        "                       kernel_size=5,\n",
        "                       strides=2,\n",
        "                       padding='same',\n",
        "                       kernel_initializer='glorot_uniform',\n",
        "                       kernel_regularizer=regularizers.l2(l=0.00001), name=conv_name)(inp)\n",
        "        o = BatchNormalization(name=conv_name + '_bn')(o)\n",
        "        o = clipped_relu(o)\n",
        "        for i in range(3):\n",
        "            o = identity_block(o, kernel_size=3, filters=filters, stage=stage, block=i)\n",
        "        return o\n",
        "\n",
        "    def cnn_component(inp):\n",
        "        x_ = conv_and_res_block(inp, 64, stage=1)\n",
        "        x_ = conv_and_res_block(x_, 128, stage=2)\n",
        "        x_ = conv_and_res_block(x_, 256, stage=3)\n",
        "        x_ = conv_and_res_block(x_, 512, stage=4)\n",
        "        return x_\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    x = cnn_component(inputs)  # shape = (BATCH_SIZE , num_frames/16, 64/16, 512)\n",
        "    \n",
        "    x = Lambda(lambda y: K.reshape(y, (-1, math.ceil(num_frames/16), 2048)), name='reshape')(x)\n",
        "    x = Lambda(lambda y: K.mean(y, axis=1), name='average')(x)  #shape = (BATCH_SIZE, 512)\n",
        "    x = Dense(512, name='affine')(x)  # .shape = (BATCH_SIZE , 512)\n",
        "    x = Lambda(lambda y: K.l2_normalize(y, axis=1), name='ln')(x)\n",
        "\n",
        "    model = Model(inputs, x, name='convolutional')\n",
        "\n",
        "    #print(model.summary())\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk1FUIJyZUWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_last_checkpoint_if_exists(checkpoint_folder):\n",
        "  os.makedirs(checkpoint_folder, exist_ok=True)\n",
        "  files = glob.glob('{}/*.h5'.format(checkpoint_folder), recursive=True)\n",
        "  if len(files) == 0:\n",
        "      return None\n",
        "  return sort_filenames(files)[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7sTDio1eMKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dir_and_delete_content(directory):\n",
        "  os.makedirs(directory, exist_ok=True)\n",
        "  files = sorted(filter(lambda f: os.path.isfile(f) and f.endswith(\".h5\"), \n",
        "      map(lambda f: os.path.join(directory, f), os.listdir(directory))),\n",
        "      key=os.path.getmtime)\n",
        "  # delete all but most current file to assure the latest model is availabel even if process is killed\n",
        "  for file in files[:-4]:\n",
        "      print(\"removing old model: {}\".format(file))\n",
        "      os.remove(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqrc_kk_Z9KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sorting the file names\n",
        "def sort_filenames(l):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
        "    return sorted(l, key=alphanum_key)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqAlSVu5aSsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating Triplet Loss\n",
        "def triplet_loss(y_true, y_pred):\n",
        "  elements = BATCH_SIZE\n",
        "  anchor = y_pred[0:elements]\n",
        "  positive_ex = y_pred[elements:2 * elements]\n",
        "  negative_ex = y_pred[2 * elements:]\n",
        "\n",
        "  sap = batch_cosine_similarity(anchor, positive_ex)\n",
        "  san = batch_cosine_similarity(anchor, negative_ex)\n",
        "  loss = K.maximum(san - sap + ALPHA, 0.0)\n",
        "  total_loss = K.sum(loss)\n",
        "  return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz4LBIWPadVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_cosine_similarity(x1, x2):\n",
        "  # https://en.wikipedia.org/wiki/Cosine_similarity\n",
        "  # 1 = equal direction ; -1 = opposite direction\n",
        "  dot = K.squeeze(K.batch_dot(x1, x2, axes=1), axis=1)\n",
        "  return dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UltGEnJa6RI",
        "colab_type": "text"
      },
      "source": [
        "# Pre-Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By5qRQiX8FQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_qXSd5kd-Ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_NEGATIVE_TEST = 99\n",
        "TEST_DIR = \"subset3_npy\"\n",
        "CHECKPOINT_FOLDER = \"drive/My Drive/MLSP2\"\n",
        "ALPHA = 0.2\n",
        "batch_size = BATCH_SIZE * TRIPLET_PER_BATCH\n",
        "SAVE_PER_EPOCHS=200\n",
        "DATA_DIR = \"subset3_npy\"\n",
        "TEST_DIR = \"vox_test_npy\"\n",
        "TEST_PER_EPOCHS = 50\n",
        "BEST_CHECKPOINT_FOLDER = \"drive/My Drive/MLSP_BEST\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_YfMwuNZT3N",
        "colab_type": "code",
        "outputId": "e6672751-aa4d-4b82-a3b3-403a89118f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data, test_data = split_data(data_npy[\"filename\"], data_npy[\"class\"], batch_size)\n",
        "train_batch_iterator = batch_training_data_generator(train_data,le, batch_size=batch_size)\n",
        "test_batch_iterator = batch_test_data_generator(test_data, le, batch_size=batch_size)\n",
        "test_steps = int(len(test_data)/batch_size)\n",
        "x_test, y_test = test_batch_iterator.__next__()\n",
        "audio_file = x_test[0]\n",
        "num_frames = audio_file.shape[0]\n",
        "print('Numer of Frames : {}'.format(num_frames))\n",
        "print('Batch Size: {}'.format(batch_size))\n",
        "no_of_speakers = len(le.classes_)\n",
        "base_model = convolutional_model(input_shape=x_test.shape[1:], batch_size=batch_size, num_frames=num_frames)\n",
        "x = base_model.output\n",
        "x = Dense(no_of_speakers, activation='softmax',name='softmax_layer')(x)\n",
        "\n",
        "model = Model(base_model.input, x)\n",
        "print(model.summary())\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numer of Frames : 399\n",
            "Batch Size: 96\n",
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 399, 64, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv64-s (Conv2D)               (None, 200, 32, 64)  1664        input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv64-s_bn (BatchNormalization (None, 200, 32, 64)  256         conv64-s[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_253 (Lambda)             (None, 200, 32, 64)  0           conv64-s_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "res1_0_branch_2a (Conv2D)       (None, 200, 32, 64)  36928       lambda_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_0_branch_2a_bn (BatchNorma (None, 200, 32, 64)  256         res1_0_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_254 (Lambda)             (None, 200, 32, 64)  0           res1_0_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res1_0_branch_2b (Conv2D)       (None, 200, 32, 64)  36928       lambda_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_0_branch_2b_bn (BatchNorma (None, 200, 32, 64)  256         res1_0_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_109 (Add)                   (None, 200, 32, 64)  0           res1_0_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_255 (Lambda)             (None, 200, 32, 64)  0           add_109[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res1_1_branch_2a (Conv2D)       (None, 200, 32, 64)  36928       lambda_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_1_branch_2a_bn (BatchNorma (None, 200, 32, 64)  256         res1_1_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_256 (Lambda)             (None, 200, 32, 64)  0           res1_1_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res1_1_branch_2b (Conv2D)       (None, 200, 32, 64)  36928       lambda_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_1_branch_2b_bn (BatchNorma (None, 200, 32, 64)  256         res1_1_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_110 (Add)                   (None, 200, 32, 64)  0           res1_1_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_257 (Lambda)             (None, 200, 32, 64)  0           add_110[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res1_2_branch_2a (Conv2D)       (None, 200, 32, 64)  36928       lambda_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_2_branch_2a_bn (BatchNorma (None, 200, 32, 64)  256         res1_2_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_258 (Lambda)             (None, 200, 32, 64)  0           res1_2_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res1_2_branch_2b (Conv2D)       (None, 200, 32, 64)  36928       lambda_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_2_branch_2b_bn (BatchNorma (None, 200, 32, 64)  256         res1_2_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_111 (Add)                   (None, 200, 32, 64)  0           res1_2_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_259 (Lambda)             (None, 200, 32, 64)  0           add_111[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv128-s (Conv2D)              (None, 100, 16, 128) 204928      lambda_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv128-s_bn (BatchNormalizatio (None, 100, 16, 128) 512         conv128-s[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_260 (Lambda)             (None, 100, 16, 128) 0           conv128-s_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2_0_branch_2a (Conv2D)       (None, 100, 16, 128) 147584      lambda_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_0_branch_2a_bn (BatchNorma (None, 100, 16, 128) 512         res2_0_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_261 (Lambda)             (None, 100, 16, 128) 0           res2_0_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2_0_branch_2b (Conv2D)       (None, 100, 16, 128) 147584      lambda_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_0_branch_2b_bn (BatchNorma (None, 100, 16, 128) 512         res2_0_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_112 (Add)                   (None, 100, 16, 128) 0           res2_0_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_262 (Lambda)             (None, 100, 16, 128) 0           add_112[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res2_1_branch_2a (Conv2D)       (None, 100, 16, 128) 147584      lambda_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_1_branch_2a_bn (BatchNorma (None, 100, 16, 128) 512         res2_1_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_263 (Lambda)             (None, 100, 16, 128) 0           res2_1_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2_1_branch_2b (Conv2D)       (None, 100, 16, 128) 147584      lambda_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_1_branch_2b_bn (BatchNorma (None, 100, 16, 128) 512         res2_1_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_113 (Add)                   (None, 100, 16, 128) 0           res2_1_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_264 (Lambda)             (None, 100, 16, 128) 0           add_113[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res2_2_branch_2a (Conv2D)       (None, 100, 16, 128) 147584      lambda_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_2_branch_2a_bn (BatchNorma (None, 100, 16, 128) 512         res2_2_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_265 (Lambda)             (None, 100, 16, 128) 0           res2_2_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2_2_branch_2b (Conv2D)       (None, 100, 16, 128) 147584      lambda_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_2_branch_2b_bn (BatchNorma (None, 100, 16, 128) 512         res2_2_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_114 (Add)                   (None, 100, 16, 128) 0           res2_2_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_266 (Lambda)             (None, 100, 16, 128) 0           add_114[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv256-s (Conv2D)              (None, 50, 8, 256)   819456      lambda_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv256-s_bn (BatchNormalizatio (None, 50, 8, 256)   1024        conv256-s[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_267 (Lambda)             (None, 50, 8, 256)   0           conv256-s_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3_0_branch_2a (Conv2D)       (None, 50, 8, 256)   590080      lambda_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_0_branch_2a_bn (BatchNorma (None, 50, 8, 256)   1024        res3_0_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_268 (Lambda)             (None, 50, 8, 256)   0           res3_0_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3_0_branch_2b (Conv2D)       (None, 50, 8, 256)   590080      lambda_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_0_branch_2b_bn (BatchNorma (None, 50, 8, 256)   1024        res3_0_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_115 (Add)                   (None, 50, 8, 256)   0           res3_0_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_269 (Lambda)             (None, 50, 8, 256)   0           add_115[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3_1_branch_2a (Conv2D)       (None, 50, 8, 256)   590080      lambda_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_1_branch_2a_bn (BatchNorma (None, 50, 8, 256)   1024        res3_1_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_270 (Lambda)             (None, 50, 8, 256)   0           res3_1_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3_1_branch_2b (Conv2D)       (None, 50, 8, 256)   590080      lambda_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_1_branch_2b_bn (BatchNorma (None, 50, 8, 256)   1024        res3_1_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_116 (Add)                   (None, 50, 8, 256)   0           res3_1_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_271 (Lambda)             (None, 50, 8, 256)   0           add_116[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3_2_branch_2a (Conv2D)       (None, 50, 8, 256)   590080      lambda_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_2_branch_2a_bn (BatchNorma (None, 50, 8, 256)   1024        res3_2_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_272 (Lambda)             (None, 50, 8, 256)   0           res3_2_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3_2_branch_2b (Conv2D)       (None, 50, 8, 256)   590080      lambda_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_2_branch_2b_bn (BatchNorma (None, 50, 8, 256)   1024        res3_2_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_117 (Add)                   (None, 50, 8, 256)   0           res3_2_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_273 (Lambda)             (None, 50, 8, 256)   0           add_117[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv512-s (Conv2D)              (None, 25, 4, 512)   3277312     lambda_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv512-s_bn (BatchNormalizatio (None, 25, 4, 512)   2048        conv512-s[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_274 (Lambda)             (None, 25, 4, 512)   0           conv512-s_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res4_0_branch_2a (Conv2D)       (None, 25, 4, 512)   2359808     lambda_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_0_branch_2a_bn (BatchNorma (None, 25, 4, 512)   2048        res4_0_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_275 (Lambda)             (None, 25, 4, 512)   0           res4_0_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4_0_branch_2b (Conv2D)       (None, 25, 4, 512)   2359808     lambda_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_0_branch_2b_bn (BatchNorma (None, 25, 4, 512)   2048        res4_0_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_118 (Add)                   (None, 25, 4, 512)   0           res4_0_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_276 (Lambda)             (None, 25, 4, 512)   0           add_118[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4_1_branch_2a (Conv2D)       (None, 25, 4, 512)   2359808     lambda_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_1_branch_2a_bn (BatchNorma (None, 25, 4, 512)   2048        res4_1_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_277 (Lambda)             (None, 25, 4, 512)   0           res4_1_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4_1_branch_2b (Conv2D)       (None, 25, 4, 512)   2359808     lambda_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_1_branch_2b_bn (BatchNorma (None, 25, 4, 512)   2048        res4_1_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_119 (Add)                   (None, 25, 4, 512)   0           res4_1_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_278 (Lambda)             (None, 25, 4, 512)   0           add_119[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4_2_branch_2a (Conv2D)       (None, 25, 4, 512)   2359808     lambda_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_2_branch_2a_bn (BatchNorma (None, 25, 4, 512)   2048        res4_2_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_279 (Lambda)             (None, 25, 4, 512)   0           res4_2_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4_2_branch_2b (Conv2D)       (None, 25, 4, 512)   2359808     lambda_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_2_branch_2b_bn (BatchNorma (None, 25, 4, 512)   2048        res4_2_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_120 (Add)                   (None, 25, 4, 512)   0           res4_2_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_280 (Lambda)             (None, 25, 4, 512)   0           add_120[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Lambda)                (None, 25, 2048)     0           lambda_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average (Lambda)                (None, 2048)         0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "affine (Dense)                  (None, 512)          1049088     average[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ln (Lambda)                     (None, 512)          0           affine[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "softmax_layer (Dense)           (None, 300)          153900      ln[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 24,339,628\n",
            "Trainable params: 24,326,188\n",
            "Non-trainable params: 13,440\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1cZSRT2a3Da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRE_CHECKPOINT_FOLDER = 'drive/My Drive/MLSP_PRE'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPN4p1vPb3e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJFnAUcRbNEQ",
        "colab_type": "code",
        "outputId": "4c4823ee-6e0a-41c2-eef9-3c124b8c63ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grad_steps = 0\n",
        "# last_checkpoint = find_last_checkpoint_if_exists(PRE_CHECKPOINT_FOLDER)\n",
        "# last_checkpoint = None\n",
        "last_checkpoint = 'drive/My Drive/model_8000_1.72135.h5'\n",
        "if last_checkpoint is not None:\n",
        "    print('Found checkpoint [{}]. Resume from here...'.format(last_checkpoint))\n",
        "    model.load_weights(last_checkpoint)\n",
        "    grad_steps = int(last_checkpoint.split('_')[-2])"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found checkpoint [drive/My Drive/model_8000_1.72135.h5]. Resume from here...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mt6-jMRbVLZ",
        "colab_type": "code",
        "outputId": "12437476-666d-44e6-86d7-1573df1a5dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "while True:\n",
        "    orig_time = time()\n",
        "    # Gettting next batch from iterator\n",
        "    x_train, y_train = train_batch_iterator.__next__()\n",
        "    [loss, acc] = model.train_on_batch(x_train, y_train)  # return [loss, acc]\n",
        "    print('Train Steps:{0}, Time:{1:.2f}s, Loss={2}, Accuracy={3}'.format(grad_steps,time() - orig_time, loss,acc))\n",
        "\n",
        "    if grad_steps % TEST_PER_EPOCHS == 0:\n",
        "        losses = []; accs = []\n",
        "        for ss in range(test_steps):\n",
        "            [loss, acc] = model.test_on_batch(x_test, y_test)\n",
        "            x_test, y_test = test_batch_iterator.__next__()\n",
        "            losses.append(loss); accs.append(acc)\n",
        "        loss = np.mean(np.array(losses)); acc = np.mean(np.array(accs))\n",
        "        print('Test the Data ---------- Steps:{0}, Loss={1}, Accuracy={2}, '.format(grad_steps,loss,acc))\n",
        "\n",
        "    if grad_steps  % SAVE_PER_EPOCHS == 0:\n",
        "        create_dir_and_delete_content(PRE_CHECKPOINT_FOLDER)\n",
        "        model.save_weights('{0}/model_{1}_{2:.5f}.h5'.format(PRE_CHECKPOINT_FOLDER, grad_steps, loss))\n",
        "\n",
        "    grad_steps += 1"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Steps:8000, Time:16.23s, Loss=1.8429365158081055, Accuracy=0.6666666865348816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-172-ac7b6e12db32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSHUr5q3a9wu",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IdUIJL07zGc",
        "colab_type": "code",
        "outputId": "91642c75-c4c0-49f4-bf1f-2343ce6a0d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_npy = create_catalogue(\"subset3_npy\",\"*.npy\",flag=True) \n",
        "unique_speakers = data_npy[\"class\"].unique()\n",
        "batch = stochastic_mini_batch(data_npy, batch_size=BATCH_SIZE, unique_speakers=unique_speakers)\n",
        "batch_size = BATCH_SIZE * TRIPLET_PER_BATCH\n",
        "x, y = batch.to_inputs()"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieved 44998 files with 300 different speakers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RT0APs37_0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_file = x[0]\n",
        "num_frames = audio_file.shape[0]\n",
        "train_batch_size = batch_size\n",
        "#batch_shape = [batch_size * num_frames] + list(audio_file.shape[1:])  # A triplet has 3 parts.\n",
        "input_shape = (num_frames, audio_file.shape[1], audio_file.shape[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrdyB8zv8ELG",
        "colab_type": "code",
        "outputId": "08ea638c-ff94-4077-c654-9d610502f567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = convolutional_model(input_shape=input_shape, batch_size=batch_size, num_frames=num_frames)\n",
        "model.summary()"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"convolutional\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 399, 64, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv64-s (Conv2D)               (None, 200, 32, 64)  1664        input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv64-s_bn (BatchNormalization (None, 200, 32, 64)  256         conv64-s[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_281 (Lambda)             (None, 200, 32, 64)  0           conv64-s_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "res1_0_branch_2a (Conv2D)       (None, 200, 32, 64)  36928       lambda_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_0_branch_2a_bn (BatchNorma (None, 200, 32, 64)  256         res1_0_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_282 (Lambda)             (None, 200, 32, 64)  0           res1_0_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res1_0_branch_2b (Conv2D)       (None, 200, 32, 64)  36928       lambda_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_0_branch_2b_bn (BatchNorma (None, 200, 32, 64)  256         res1_0_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_121 (Add)                   (None, 200, 32, 64)  0           res1_0_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_283 (Lambda)             (None, 200, 32, 64)  0           add_121[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res1_1_branch_2a (Conv2D)       (None, 200, 32, 64)  36928       lambda_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_1_branch_2a_bn (BatchNorma (None, 200, 32, 64)  256         res1_1_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_284 (Lambda)             (None, 200, 32, 64)  0           res1_1_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res1_1_branch_2b (Conv2D)       (None, 200, 32, 64)  36928       lambda_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_1_branch_2b_bn (BatchNorma (None, 200, 32, 64)  256         res1_1_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_122 (Add)                   (None, 200, 32, 64)  0           res1_1_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_285 (Lambda)             (None, 200, 32, 64)  0           add_122[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res1_2_branch_2a (Conv2D)       (None, 200, 32, 64)  36928       lambda_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_2_branch_2a_bn (BatchNorma (None, 200, 32, 64)  256         res1_2_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_286 (Lambda)             (None, 200, 32, 64)  0           res1_2_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res1_2_branch_2b (Conv2D)       (None, 200, 32, 64)  36928       lambda_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res1_2_branch_2b_bn (BatchNorma (None, 200, 32, 64)  256         res1_2_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_123 (Add)                   (None, 200, 32, 64)  0           res1_2_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_287 (Lambda)             (None, 200, 32, 64)  0           add_123[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv128-s (Conv2D)              (None, 100, 16, 128) 204928      lambda_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv128-s_bn (BatchNormalizatio (None, 100, 16, 128) 512         conv128-s[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_288 (Lambda)             (None, 100, 16, 128) 0           conv128-s_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2_0_branch_2a (Conv2D)       (None, 100, 16, 128) 147584      lambda_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_0_branch_2a_bn (BatchNorma (None, 100, 16, 128) 512         res2_0_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_289 (Lambda)             (None, 100, 16, 128) 0           res2_0_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2_0_branch_2b (Conv2D)       (None, 100, 16, 128) 147584      lambda_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_0_branch_2b_bn (BatchNorma (None, 100, 16, 128) 512         res2_0_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_124 (Add)                   (None, 100, 16, 128) 0           res2_0_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_290 (Lambda)             (None, 100, 16, 128) 0           add_124[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res2_1_branch_2a (Conv2D)       (None, 100, 16, 128) 147584      lambda_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_1_branch_2a_bn (BatchNorma (None, 100, 16, 128) 512         res2_1_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_291 (Lambda)             (None, 100, 16, 128) 0           res2_1_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2_1_branch_2b (Conv2D)       (None, 100, 16, 128) 147584      lambda_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_1_branch_2b_bn (BatchNorma (None, 100, 16, 128) 512         res2_1_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_125 (Add)                   (None, 100, 16, 128) 0           res2_1_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_292 (Lambda)             (None, 100, 16, 128) 0           add_125[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res2_2_branch_2a (Conv2D)       (None, 100, 16, 128) 147584      lambda_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_2_branch_2a_bn (BatchNorma (None, 100, 16, 128) 512         res2_2_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_293 (Lambda)             (None, 100, 16, 128) 0           res2_2_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2_2_branch_2b (Conv2D)       (None, 100, 16, 128) 147584      lambda_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2_2_branch_2b_bn (BatchNorma (None, 100, 16, 128) 512         res2_2_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_126 (Add)                   (None, 100, 16, 128) 0           res2_2_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_294 (Lambda)             (None, 100, 16, 128) 0           add_126[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv256-s (Conv2D)              (None, 50, 8, 256)   819456      lambda_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv256-s_bn (BatchNormalizatio (None, 50, 8, 256)   1024        conv256-s[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_295 (Lambda)             (None, 50, 8, 256)   0           conv256-s_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3_0_branch_2a (Conv2D)       (None, 50, 8, 256)   590080      lambda_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_0_branch_2a_bn (BatchNorma (None, 50, 8, 256)   1024        res3_0_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_296 (Lambda)             (None, 50, 8, 256)   0           res3_0_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3_0_branch_2b (Conv2D)       (None, 50, 8, 256)   590080      lambda_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_0_branch_2b_bn (BatchNorma (None, 50, 8, 256)   1024        res3_0_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_127 (Add)                   (None, 50, 8, 256)   0           res3_0_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_297 (Lambda)             (None, 50, 8, 256)   0           add_127[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3_1_branch_2a (Conv2D)       (None, 50, 8, 256)   590080      lambda_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_1_branch_2a_bn (BatchNorma (None, 50, 8, 256)   1024        res3_1_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_298 (Lambda)             (None, 50, 8, 256)   0           res3_1_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3_1_branch_2b (Conv2D)       (None, 50, 8, 256)   590080      lambda_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_1_branch_2b_bn (BatchNorma (None, 50, 8, 256)   1024        res3_1_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_128 (Add)                   (None, 50, 8, 256)   0           res3_1_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_299 (Lambda)             (None, 50, 8, 256)   0           add_128[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3_2_branch_2a (Conv2D)       (None, 50, 8, 256)   590080      lambda_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_2_branch_2a_bn (BatchNorma (None, 50, 8, 256)   1024        res3_2_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_300 (Lambda)             (None, 50, 8, 256)   0           res3_2_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3_2_branch_2b (Conv2D)       (None, 50, 8, 256)   590080      lambda_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3_2_branch_2b_bn (BatchNorma (None, 50, 8, 256)   1024        res3_2_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_129 (Add)                   (None, 50, 8, 256)   0           res3_2_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_301 (Lambda)             (None, 50, 8, 256)   0           add_129[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv512-s (Conv2D)              (None, 25, 4, 512)   3277312     lambda_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv512-s_bn (BatchNormalizatio (None, 25, 4, 512)   2048        conv512-s[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_302 (Lambda)             (None, 25, 4, 512)   0           conv512-s_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res4_0_branch_2a (Conv2D)       (None, 25, 4, 512)   2359808     lambda_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_0_branch_2a_bn (BatchNorma (None, 25, 4, 512)   2048        res4_0_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_303 (Lambda)             (None, 25, 4, 512)   0           res4_0_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4_0_branch_2b (Conv2D)       (None, 25, 4, 512)   2359808     lambda_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_0_branch_2b_bn (BatchNorma (None, 25, 4, 512)   2048        res4_0_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_130 (Add)                   (None, 25, 4, 512)   0           res4_0_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_304 (Lambda)             (None, 25, 4, 512)   0           add_130[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4_1_branch_2a (Conv2D)       (None, 25, 4, 512)   2359808     lambda_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_1_branch_2a_bn (BatchNorma (None, 25, 4, 512)   2048        res4_1_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_305 (Lambda)             (None, 25, 4, 512)   0           res4_1_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4_1_branch_2b (Conv2D)       (None, 25, 4, 512)   2359808     lambda_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_1_branch_2b_bn (BatchNorma (None, 25, 4, 512)   2048        res4_1_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_131 (Add)                   (None, 25, 4, 512)   0           res4_1_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_306 (Lambda)             (None, 25, 4, 512)   0           add_131[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4_2_branch_2a (Conv2D)       (None, 25, 4, 512)   2359808     lambda_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_2_branch_2a_bn (BatchNorma (None, 25, 4, 512)   2048        res4_2_branch_2a[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_307 (Lambda)             (None, 25, 4, 512)   0           res4_2_branch_2a_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4_2_branch_2b (Conv2D)       (None, 25, 4, 512)   2359808     lambda_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4_2_branch_2b_bn (BatchNorma (None, 25, 4, 512)   2048        res4_2_branch_2b[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_132 (Add)                   (None, 25, 4, 512)   0           res4_2_branch_2b_bn[0][0]        \n",
            "                                                                 lambda_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_308 (Lambda)             (None, 25, 4, 512)   0           add_132[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Lambda)                (None, 25, 2048)     0           lambda_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average (Lambda)                (None, 2048)         0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "affine (Dense)                  (None, 512)          1049088     average[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ln (Lambda)                     (None, 512)          0           affine[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 24,185,728\n",
            "Trainable params: 24,172,288\n",
            "Non-trainable params: 13,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1AcJGtHEsEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_NEGATIVE_TEST = 99\n",
        "TEST_DIR = \"vox_test_npy\"\n",
        "CHECKPOINT_FOLDER = \"drive/My Drive\"\n",
        "ALPHA = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apbhkh0914t-",
        "colab_type": "text"
      },
      "source": [
        "## Loading Pre-training weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R85HAZeb6h7K",
        "colab_type": "code",
        "outputId": "a7a7f6be-e574-43d9-f8e1-17c71e8aca27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "last_checkpoint = find_last_checkpoint_if_exists(PRE_CHECKPOINT_FOLDER)\n",
        "last_checkpoint = \"drive/My Drive/model_8000_1.72135.h5\"\n",
        "if last_checkpoint is not None:\n",
        "    print('Found pre-training checkpoint [{}]. Resume from here...'.format(last_checkpoint))\n",
        "    x = model.output\n",
        "    x = Dense(len(unique_speakers), activation='softmax', name='softmax_layer')(x)\n",
        "    pre_model = Model(model.input, x)\n",
        "    pre_model.load_weights(last_checkpoint)\n",
        "    grad_steps = int(last_checkpoint.split('_')[-2])\n",
        "    print('Successfully loaded pre-training model')"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found pre-training checkpoint [drive/My Drive/model_8000_1.72135.h5]. Resume from here...\n",
            "Successfully loaded pre-training model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYalppEeE0tK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grad_steps=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cub5P7f2AMq",
        "colab_type": "text"
      },
      "source": [
        "Loading Checkpoints for Pretraining + triplet Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssjTaPxzEHhV",
        "colab_type": "code",
        "outputId": "d5d9749f-c3dd-4cc3-9c3e-ad9f9f8778fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# last_checkpoint = find_last_checkpoint_if_exists(CHECKPOINT_FOLDER)\n",
        "last_checkpoint = \"drive/My Drive/model_1152_0.21762_0.17803.h5\"\n",
        "if last_checkpoint is not None:\n",
        "    print('Found checkpoint [{}]. Resume from here...'.format(last_checkpoint))\n",
        "    model.load_weights(last_checkpoint)\n",
        "    grad_steps = int(last_checkpoint.split('_')[-3])\n",
        "    min_loss = float(last_checkpoint.split('_')[-2].split(\".\")[0])\n",
        "else:\n",
        "    min_loss = float('inf')"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found checkpoint [drive/My Drive/model_1152_0.21762_0.17803.h5]. Resume from here...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHbBHdIc8t4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(optimizer='adam', loss=triplet_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g8Largs83qM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from shutil import copyfile\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPmPkKZraghe",
        "colab_type": "code",
        "outputId": "80434d2d-b5bb-446d-cafe-be5da6c3d07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "steps = 0\n",
        "max_steps = 1000\n",
        "hist_loss = {}\n",
        "while steps<max_steps:\n",
        "    steps+=1\n",
        "    batch = stochastic_mini_batch(data_npy, batch_size=BATCH_SIZE, unique_speakers=unique_speakers)\n",
        "    batch_size = BATCH_SIZE * TRIPLET_PER_BATCH\n",
        "    x, _ = batch.to_inputs()\n",
        "    y = np.random.uniform(size=(x.shape[0], 1))\n",
        "    loss = model.train_on_batch(x, y)\n",
        "    print(\"Step\",grad_steps,loss)\n",
        "    hist_loss[grad_steps]=loss\n",
        "  \n",
        "    #checkpoint to save weights\n",
        "    if (grad_steps ) % SAVE_PER_EPOCHS == 0:\n",
        "        create_dir_and_delete_content(CHECKPOINT_FOLDER)\n",
        "        model.save_weights('{0}/model_{1}_{2:.5f}.h5'.format(CHECKPOINT_FOLDER, grad_steps, loss))\n",
        "    grad_steps += 1"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1152 0.5489491\n",
            "Step 1153 0.4757245\n",
            "Step 1154 0.6082143\n",
            "Step 1155 0.45742002\n",
            "Step 1156 0.77682966\n",
            "Step 1157 0.33235633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-183-0fcddb0f5a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstochastic_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_npy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_speakers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_speakers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTRIPLET_PER_BATCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-144-be8564b6fdb2>\u001b[0m in \u001b[0;36mstochastic_mini_batch\u001b[0;34m(data, batch_size, unique_speakers)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstochastic_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_speakers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_speakers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-144-be8564b6fdb2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, batch_size, unique_speakers)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mnegative_speaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_different_speakers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#print(two_different_speakers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0manchor_positive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0manchor_positive_speaker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0manchor_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_positive_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0manchor_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'anchor'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2984\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3037\u001b[0m         \u001b[0;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3039\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3040\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bO4XCSTcZAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhc0TOxIWp-a",
        "colab_type": "text"
      },
      "source": [
        "# Testing Embeddings on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ5sUqmts5kR",
        "colab_type": "text"
      },
      "source": [
        "Using the 40 speaker test subset to train a SVC classifier on ttop of speaker embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcHxXQ4eWsku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "469144a0-5255-4fa3-c9a0-b3411bf20a49"
      },
      "source": [
        "!cp drive/My\\ Drive/vox_test_npy.zip .\n",
        "!unzip -q vox_test_npy.zip"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace vox_test_npy/id10292_29.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln0nWPcKWwjt",
        "colab_type": "code",
        "outputId": "7636b442-5111-41a0-8bc2-d607a5674d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t     subset3_npy      train_loss_acc.txt  vox_test_npy.zip\n",
            "sample_data  subset3_npy.zip  vox_test_npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PeViLGgaUQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model_checkpoint = \"drive/My Drive/model_1152_0.21762_0.17803.h5\"\n",
        "#best_model_checkpoint = \"drive/My Drive/MLSP/model_4000_2.21986.h5\"\n",
        "if best_model_checkpoint is not None:\n",
        "    model.load_weights(best_model_checkpoint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd6TBalXbKfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "f947e192-4600-48b3-e88e-687dc7ae9908"
      },
      "source": [
        "test_catalog = create_catalogue(\"vox_test_npy\",\"*.npy\",flag=True)\n",
        "test_catalog"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieved 4874 files with 40 different speakers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vox_test_npy/id10289_26.npy</td>\n",
              "      <td>id10289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vox_test_npy/id10273_182.npy</td>\n",
              "      <td>id10273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vox_test_npy/id10275_66.npy</td>\n",
              "      <td>id10275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vox_test_npy/id10273_21.npy</td>\n",
              "      <td>id10273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vox_test_npy/id10271_67.npy</td>\n",
              "      <td>id10271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4869</th>\n",
              "      <td>vox_test_npy/id10307_151.npy</td>\n",
              "      <td>id10307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4870</th>\n",
              "      <td>vox_test_npy/id10305_42.npy</td>\n",
              "      <td>id10305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4871</th>\n",
              "      <td>vox_test_npy/id10298_19.npy</td>\n",
              "      <td>id10298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4872</th>\n",
              "      <td>vox_test_npy/id10309_27.npy</td>\n",
              "      <td>id10309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4873</th>\n",
              "      <td>vox_test_npy/id10302_130.npy</td>\n",
              "      <td>id10302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4874 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          filename    class\n",
              "0      vox_test_npy/id10289_26.npy  id10289\n",
              "1     vox_test_npy/id10273_182.npy  id10273\n",
              "2      vox_test_npy/id10275_66.npy  id10275\n",
              "3      vox_test_npy/id10273_21.npy  id10273\n",
              "4      vox_test_npy/id10271_67.npy  id10271\n",
              "...                            ...      ...\n",
              "4869  vox_test_npy/id10307_151.npy  id10307\n",
              "4870   vox_test_npy/id10305_42.npy  id10305\n",
              "4871   vox_test_npy/id10298_19.npy  id10298\n",
              "4872   vox_test_npy/id10309_27.npy  id10309\n",
              "4873  vox_test_npy/id10302_130.npy  id10302\n",
              "\n",
              "[4874 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8AmlN8LjWuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUDBlUFfjZdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le2 = LabelEncoder()\n",
        "test_catalog[\"class\"] = le2.fit_transform(test_catalog[\"class\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G15LM3sUnsTE",
        "colab_type": "code",
        "outputId": "12bf2f72-8056-4297-e751-42ee4683ddb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "le2.classes_"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['id10270', 'id10271', 'id10272', 'id10273', 'id10274', 'id10275',\n",
              "       'id10276', 'id10277', 'id10278', 'id10279', 'id10280', 'id10281',\n",
              "       'id10282', 'id10283', 'id10284', 'id10285', 'id10286', 'id10287',\n",
              "       'id10288', 'id10289', 'id10290', 'id10291', 'id10292', 'id10293',\n",
              "       'id10294', 'id10295', 'id10296', 'id10297', 'id10298', 'id10299',\n",
              "       'id10300', 'id10301', 'id10302', 'id10303', 'id10304', 'id10305',\n",
              "       'id10306', 'id10307', 'id10308', 'id10309'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYKC9lKNq6sI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_model_batch(model,inp,batch_size=10):\n",
        "  i = 0\n",
        "  embedding = None\n",
        "  while i < len(inp) and i+batch_size<len(inp):\n",
        "    subset = inp[i:i+batch_size]\n",
        "    sub_embed = model.predict_on_batch(subset)\n",
        "    if embedding is None:\n",
        "        embedding = sub_embed\n",
        "    else:\n",
        "        embedding = np.concatenate([embedding, sub_embed], axis=0)\n",
        "    i+=batch_size\n",
        "  if i<len(inp):\n",
        "    subset = inp[i:]\n",
        "    sub_embed = model.predict_on_batch(subset)\n",
        "    if embedding is None:\n",
        "        embedding = sub_embed\n",
        "    else:\n",
        "        embedding = np.concatenate([embedding, sub_embed], axis=0)\n",
        "  return embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv-V8AkRdMoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_balanced_and_load_data(data,samples_per_class,model=None,batch_size=10,top_classes=None,seed=999):\n",
        "  if top_classes is None:\n",
        "    classes = data[\"class\"].unique()\n",
        "  else:\n",
        "    classes = data[\"class\"].value_counts()[:top_classes].index.to_list()\n",
        "    data = data[data[\"class\"].isin(classes)]\n",
        "  train = pd.DataFrame()\n",
        "  removed_indices = []\n",
        "  for cl in classes:\n",
        "    data_class = data[data[\"class\"]==cl]\n",
        "    #distributing data evenly for classes with lesser utterances\n",
        "    if samples_per_class<len(data_class)/2:\n",
        "      sample = data_class.sample(samples_per_class,random_state=seed)\n",
        "      removed_indices.extend(sample.index.to_list())\n",
        "      train = pd.concat([train,sample], axis=0)\n",
        "    else:\n",
        "      sample = data_class.sample(int(len(data_class)/2),random_state=seed)\n",
        "      removed_indices.extend(sample.index.to_list())\n",
        "      train = pd.concat([train,sample], axis=0)\n",
        "  test = data.loc[~data.index.isin(removed_indices)]\n",
        "  train = train.reset_index(drop=True)\n",
        "  test = test.reset_index(drop=True)\n",
        "  trainX, trainY, testX, testY = np.array(train[\"filename\"]),np.array(train[\"class\"]),np.array(test[\"filename\"]),np.array(test[\"class\"])\n",
        "\n",
        "  if model is not None:\n",
        "    trainX = predict_model_batch(model,np.array([np.load(x) for x in trainX]),batch_size=batch_size)\n",
        "    testX = predict_model_batch(model,np.array([np.load(x) for x in testX]),batch_size=batch_size)\n",
        "  else:\n",
        "    trainX = np.array([np.load(x) for x in trainX])\n",
        "    testX = np.array([np.load(x) for x in testX])\n",
        "    trainX = np.reshape(trainX,(trainX.shape[0],trainX.shape[1]*trainX.shape[2]*trainX.shape[3]))\n",
        "    testX = np.reshape(testX,(testX.shape[0],testX.shape[1]*testX.shape[2]*testX.shape[3]))\n",
        "  return trainX, trainY, testX, testY\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XInqNQlQv1nW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = model\n",
        "#change this for smaller samples\n",
        "samples_per_class = 80\n",
        "num_classes = len(test_catalog[\"class\"].unique())\n",
        "top_classes = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdFKRIo5iW_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX, trainY, testX, testY = split_balanced_and_load_data(test_catalog,samples_per_class,best_model,batch_size=20,top_classes=top_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeNXn6ReqBhi",
        "colab_type": "code",
        "outputId": "ffba8311-9ac8-49a6-fe2a-17d2627c68f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(trainX.shape,trainY.shape,testX.shape,testY.shape)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2168, 512) (2168,) (2706, 512) (2706,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV7BC1ObogGH",
        "colab_type": "code",
        "outputId": "8907240d-343c-4920-e9ff-c2a70d05b902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC()\n",
        "clf.fit(trainX,trainY)\n",
        "y_pred = clf.predict(testX)\n",
        "accuracy_score(testY,y_pred)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.803030303030303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej0Dtb5NS6KH",
        "colab_type": "text"
      },
      "source": [
        "# Test Own Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaAVZ1E3sYp3",
        "colab_type": "text"
      },
      "source": [
        "We recorded ourselves speaking and computed the cosine similarity between same speaker and different speaker. We then compared the cosine similarity after feature embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRQDR-dpXwC-",
        "colab_type": "code",
        "outputId": "87c52b3e-cccc-4ed5-b6fb-a5fee2d76179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "!pip uninstall matplotlib\n",
        "!pip install matplotlib==3.0.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling matplotlib-3.1.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/matplotlib-3.1.1-py3.6-nspkg.pth\n",
            "    /usr/local/lib/python3.6/dist-packages/matplotlib-3.1.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/matplotlib/*\n",
            "    /usr/local/lib/python3.6/dist-packages/mpl_toolkits/axes_grid/*\n",
            "    /usr/local/lib/python3.6/dist-packages/mpl_toolkits/axes_grid1/*\n",
            "    /usr/local/lib/python3.6/dist-packages/mpl_toolkits/axisartist/*\n",
            "    /usr/local/lib/python3.6/dist-packages/mpl_toolkits/mplot3d/*\n",
            "    /usr/local/lib/python3.6/dist-packages/mpl_toolkits/tests/*\n",
            "    /usr/local/lib/python3.6/dist-packages/pylab.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled matplotlib-3.1.1\n",
            "Collecting matplotlib==3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/89/dd823436a5f8d5ca9304b51b554863bfd366ca84708d5812f5ee87c923bc/matplotlib-3.0.0-cp36-cp36m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     || 12.8MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.0) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.0) (1.17.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.0) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.0) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib==3.0.0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.0.0) (41.6.0)\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement matplotlib!=3.0.0,>=1.5.1, but you'll have matplotlib 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: scikit-image 0.15.0 has requirement matplotlib!=3.0.0,>=2.0.0, but you'll have matplotlib 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: matplotlib\n",
            "Successfully installed matplotlib-3.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "potSujo5ZiAX",
        "colab_type": "code",
        "outputId": "9e90c855-b3f5-408a-a3ef-7622b663c7fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
            "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
            "  \"found relative to the 'datapath' directory.\".format(key))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ__sjOFTASK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r drive/My\\ Drive/sample_audio ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAOaIjrTTiAC",
        "colab_type": "code",
        "outputId": "4f6c727d-1084-4bd6-c43d-487e8bd6414e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls sample_audio/Sourabh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recording_37.wav  Recording_38.wav  Recording_39.wav  Recording_40.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XJeCjzsS7aB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r1 = load_audio('sample_audio/Rachit/1.m4a')\n",
        "r2 = load_audio('sample_audio/Rachit/2.m4a')\n",
        "r3 = load_audio('sample_audio/Rachit/3.m4a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CalapKH1Tq3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#s1 = load_audio('sample_audio/Sourabh/Recording_37.wav')\n",
        "s1 = load_audio('sample_audio/Sourabh/Recording_40.wav')\n",
        "s2 = load_audio('sample_audio/Sourabh/Recording_38.wav')\n",
        "s3 = load_audio('sample_audio/Sourabh/Recording_39.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z_lZk1uUOiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r1e, r2e, r3e = model.predict_on_batch(np.array([r1,r2,r3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X1iEJUWUbBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s1e, s2e, s3e = model.predict_on_batch(np.array([s1,s2,s3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLqWIqeFXExz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cosine_similarity([np.reshape(r1,(r1.shape[0]*r1.shape[1]))],[np.reshape(r2,(r2.shape[0]*r2.shape[1]))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqGumC_WWbF6",
        "colab_type": "code",
        "outputId": "a22dff16-eb96-4299-a7ea-72c37e458a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cosine_similarity([r1e],[r2e])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8589179]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48vZiMnzcRm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeds = [r1e,r2e,r3e,s1e,s2e,s3e]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvnn6GUccHNZ",
        "colab_type": "code",
        "outputId": "d3663aea-badc-4209-fc82-d36a5461a00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "mat = np.zeros((6,6))\n",
        "for i in range(6):\n",
        "  for j in range(6):\n",
        "    mat[i][j] = cosine_similarity([embeds[i]],[embeds[j]])[0][0]\n",
        "\n",
        "print(mat)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.00000012 0.85891789 0.91493011 0.0729316  0.17969669 0.32267368]\n",
            " [0.85891789 1.         0.92580891 0.07299769 0.16040975 0.21139029]\n",
            " [0.91493011 0.92580891 1.00000024 0.18016392 0.2488142  0.37405908]\n",
            " [0.0729316  0.07299769 0.18016392 1.00000024 0.80381113 0.66639113]\n",
            " [0.17969669 0.16040975 0.2488142  0.80381113 1.         0.74625635]\n",
            " [0.32267368 0.21139029 0.37405908 0.66639113 0.74625635 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4ow-uzIUyBd",
        "colab_type": "code",
        "outputId": "ab137f53-7579-4077-dbdf-f221e6e6ab1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "ax = sns.heatmap(mat,cmap=\"Blues\",annot=True)\n",
        "ax.set_yticklabels(np.array(['Rachit1','Rachit2','Rachit3','Sourabh1','Sourabh2','Sourabh3']),fontsize=9)\n",
        "ax.set_xticklabels(np.array(['Rachit1','Rachit2','Rachit3','Sourabh1','Sourabh2','Sourabh3']),fontsize=9)\n",
        "plt.yticks(rotation=0)\n",
        "plt.title('Cosine Similarity with Deep Speaker Embeddings')\n",
        "plt.savefig('Cosine Similarity with Deep Speaker Embeddings.png',dpi=1000,bbox_inches='tight')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEHCAYAAABGNUbLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzvjjSFQZfr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ORjjUBQDYiDi",
        "colab": {}
      },
      "source": [
        "embeds = [r1,r2,r3,s1,s2,s3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a5b6b2ad-999d-4611-9b28-cb62db9904ac",
        "id": "r1Q5K2zEYiDo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "mat = np.zeros((6,6))\n",
        "for i in range(6):\n",
        "  for j in range(6):\n",
        "    mat[i][j] = cosine_similarity([np.reshape(embeds[i],(embeds[i].shape[0]*embeds[i].shape[1]))],[np.reshape(embeds[j],(embeds[j].shape[0]*embeds[j].shape[1]))])[0][0]\n",
        "\n",
        "print(mat)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.14019943 0.16297763 0.05252644 0.07126967 0.01359652]\n",
            " [0.14019943 1.         0.21356897 0.09404561 0.08986231 0.06221868]\n",
            " [0.16297763 0.21356897 1.         0.06858588 0.07442401 0.07572561]\n",
            " [0.05252644 0.09404561 0.06858588 1.         0.14692026 0.24010757]\n",
            " [0.07126967 0.08986231 0.07442401 0.14692026 1.         0.12192221]\n",
            " [0.01359652 0.06221868 0.07572561 0.24010757 0.12192221 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2f4a754b-38c6-47d4-af15-c946896624eb",
        "id": "nSBO2vl8YiDq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "ax = sns.heatmap(mat,cmap=\"Blues\",annot=True)\n",
        "ax.set_yticklabels(np.array(['Rachit1','Rachit2','Rachit3','Sourabh1','Sourabh2','Sourabh3']),fontsize=9)\n",
        "ax.set_xticklabels(np.array(['Rachit1','Rachit2','Rachit3','Sourabh1','Sourabh2','Sourabh3']),fontsize=9)\n",
        "plt.yticks(rotation=0)\n",
        "plt.title('Cosine Similarity after Feature Extraction')\n",
        "plt.savefig('Cosine Similarity after Feature Extraction.png',dpi=1000,bbox_inches='tight')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEHCAYAAABGNUbLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}